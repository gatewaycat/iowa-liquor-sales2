{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auxiliary notebook to product markdown tables for README"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "if (!(\"Notification\" in window)) {\n",
       "    alert(\"This browser does not support desktop notifications, so the %%notify magic will not work.\");\n",
       "} else if (Notification.permission !== 'granted' && Notification.permission !== 'denied') {\n",
       "    Notification.requestPermission(function (permission) {\n",
       "        if(!('permission' in Notification)) {\n",
       "            Notification.permission = permission;\n",
       "        }\n",
       "    })\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###############################################################################\n",
    "\n",
    "## Load packages (5s)\n",
    "!pip install -q jupyternotify\n",
    "!pip install -q nest_asyncio\n",
    "!pip install -q tabulate\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "import jupyternotify\n",
    "import nest_asyncio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "get_ipython().register_magics(jupyternotify.JupyterNotifyMagics)\n",
    "# %autonotify -a 30\n",
    "nest_asyncio.apply()\n",
    "warnings.filterwarnings(\"ignore\") # For extraneous pd warnings\n",
    "\n",
    "def mysummary(df):\n",
    "    df_dtypes = df.dtypes\n",
    "    df_isna = df.isna().sum()\n",
    "    df_0 = df.iloc[0].T.astype('str')\n",
    "    df_summary = pd.DataFrame({\n",
    "        'Type':df_dtypes,\n",
    "        'Missing Entries':df_isna,\n",
    "        'First Row of Data':df_0})\n",
    "    return df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.24 s, sys: 535 ms, total: 2.77 s\n",
      "Wall time: 1.77 s\n",
      "CPU times: user 59.6 s, sys: 40.8 s, total: 1min 40s\n",
      "Wall time: 2min 14s\n",
      "CPU times: user 20.6 s, sys: 11.7 s, total: 32.3 s\n",
      "Wall time: 43.2 s\n",
      "CPU times: user 1min 35s, sys: 12.6 s, total: 1min 48s\n",
      "Wall time: 1min 59s\n",
      "CPU times: user 47.6 s, sys: 6.41 s, total: 54.1 s\n",
      "Wall time: 1min 5s\n",
      "CPU times: user 1min 21s, sys: 1min 13s, total: 2min 34s\n",
      "Wall time: 3min 23s\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"e3f16b68-e4d4-44fa-9a43-5ea9e0d76864\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"e3f16b68-e4d4-44fa-9a43-5ea9e0d76864\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"Cell execution has finished!\"};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 11s, sys: 2min 26s, total: 7min 37s\n",
      "Wall time: 9min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%notify\n",
    "\n",
    "## Load data (2min)\n",
    "%time downsample = pd.read_parquet('downsample.parquet')\n",
    "%time df = pd.read_parquet('data.parquet')\n",
    "\n",
    "## Compute summary stats (2min)\n",
    "df_dtypes = df.dtypes\n",
    "df_0 = df.iloc[0].T.astype('str')\n",
    "%time df_isna = df.isna().sum() # (30s)\n",
    "%time df_describe = df.describe(include='all', percentiles=[0.0001,.9999])\n",
    "df_describe = df_describe.T.fillna('') # (1min 30s)\n",
    "df_dtypes_isna_0 = pd.concat([df_dtypes, df_isna, df_0], axis=1)\n",
    "df_dtypes_isna_0.columns = ['dtype','null count','iloc[0]']\n",
    "df_stats = pd.concat([df_dtypes_isna_0, df_describe], axis=1)\n",
    "\n",
    "## Summarize datafiles stats (3min)\n",
    "%time len_raw = len(pd.read_csv('raw.csv',dtype='object',usecols=[0])) # (1min)\n",
    "%time df = pd.read_parquet('data.parquet') # (2min)\n",
    "len_data = len(df)\n",
    "len_nonanomalous = len(df) - df.Anomalous.sum()\n",
    "len_downsample = len(pd.read_parquet('downsample.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|      | dtype          |    count |   null count |   unique | top                 |   freq | first               | last                |\n",
      "|:-----|:---------------|---------:|-------------:|---------:|:--------------------|-------:|:--------------------|:--------------------|\n",
      "| Date | datetime64[ns] | 19883991 |            0 |     2157 | 2017-12-22 00:00:00 |  16674 | 2012-01-03 00:00:00 | 2020-10-30 00:00:00 |\n",
      "\n",
      "|                 | dtype   |    count |   null count |   unique | top                          |     freq |\n",
      "|:----------------|:--------|---------:|-------------:|---------:|:-----------------------------|---------:|\n",
      "| Invoice         | object  | 19883991 |            0 | 19883991 | 124889500022                 |        1 |\n",
      "| Store_num       | object  | 19883991 |            0 |     2495 | 2633                         |   169816 |\n",
      "| Store           | object  | 19883991 |            0 |     2613 | Hy-Vee #3 / Bdi / Des Moines |   169816 |\n",
      "| Address         | object  | 19804064 |        79927 |     2415 | 3221 Se 14Th St              |   231054 |\n",
      "| City            | object  | 19804065 |        79926 |      456 | Des Moines                   |  1730907 |\n",
      "| Zip             | object  | 19804020 |        79971 |      489 | 50010                        |   491093 |\n",
      "| County_num      | object  | 19727260 |       156731 |      108 | 77                           |  3622703 |\n",
      "| County          | object  | 19727262 |       156729 |      104 | Polk                         |  3622703 |\n",
      "| Subcategory_num | object  | 19867017 |        16974 |      110 | 1012100                      |  1916720 |\n",
      "| Subcategory     | object  | 19858951 |        25040 |      110 | Canadian Whiskies            |  1916720 |\n",
      "| Vendor_num      | object  | 19883991 |            0 |      362 | 260                          |  3356016 |\n",
      "| Vendor          | object  | 19883991 |            0 |      452 | Diageo Americas              |  3356016 |\n",
      "| Item_num        | object  | 19883991 |            0 |     9774 | 11788                        |   200245 |\n",
      "| Item            | object  | 19883991 |            0 |     8666 | Black Velvet                 |   515736 |\n",
      "| Category        | object  | 19597340 |       286651 |        9 | Whiskey                      |  5394096 |\n",
      "| Anomalous       | bool    | 19883991 |            0 |        2 | False                        | 18409105 |\n",
      "\n",
      "|               | dtype   |    count |   null count |   mean |   std |   min |   0.01% |   99.99% |      max |\n",
      "|:--------------|:--------|---------:|-------------:|-------:|------:|------:|--------:|---------:|---------:|\n",
      "| Bottle_pack   | int16   | 19883991 |            0 |     12 |     8 |     1 |       1 |       48 |      336 |\n",
      "| Bottle_mL     | int32   | 19883991 |            0 |    911 |   663 |     0 |      50 |     3600 |   378000 |\n",
      "| Bottle_cost   | int32   | 19883991 |            0 |    995 |  1074 |     0 |       0 |    14525 |   768000 |\n",
      "| Bottle_retail | int32   | 19883991 |            0 |   1494 |  1610 |     0 |       0 |    21788 |  1152000 |\n",
      "| Bottle_count  | int16   | 19883991 |            0 |     10 |    28 |     0 |       1 |      804 |    15000 |\n",
      "| Cents         | int32   | 19883991 |            0 |  13527 | 47022 |     0 |       0 |  1620000 | 27955728 |\n",
      "| mL            | int32   | 19883991 |            0 |   9137 | 33778 |     0 |      50 |  1050000 | 15000000 |\n",
      "| Gallons       | float32 | 19883991 |            0 |      2 |     9 |     0 |       0 |      277 |     3963 |\n",
      "| Longitude     | float32 | 17976922 |      1907069 |    -91 |     3 |  -105 |     -97 |      -90 |      -74 |\n",
      "| Latitude      | float32 | 17976922 |      1907069 |     42 |     1 |    39 |      40 |       43 |       45 |\n",
      "| Random | float64 | 19883991.0 |            0 |    0.5 |   0.3 |   0.0 |     0.0 |      1.0 |   1.0 |\n",
      "\n",
      "|                | filename           | filesize   |   number of rows |\n",
      "|:---------------|:-------------------|:-----------|-----------------:|\n",
      "| Raw data       | raw.csv            | 4.5G       |         19884006 |\n",
      "| Cleaned data   | data.parquet       | 848M       |         19883991 |\n",
      "| (nonanomalous) |                    |            |         18409105 |\n",
      "| 5% Downsample  | downsample.parquet | 47M        |           993222 |\n"
     ]
    }
   ],
   "source": [
    "## Convert summary stats to markdown\n",
    "def to_markdown(dtypes, columns, floatfmt='.0f'):    \n",
    "    return df_stats.loc[\n",
    "        df_stats.dtype.astype('str').isin(dtypes),\n",
    "        ['dtype','count','null count'] + columns\n",
    "    ].to_markdown(floatfmt=floatfmt)\n",
    "print(to_markdown(\n",
    "    ['datetime64[ns]'],\n",
    "    ['unique','top','freq','first','last']))\n",
    "print()\n",
    "print(to_markdown(\n",
    "    ['object','bool'],\n",
    "    ['unique','top','freq']))\n",
    "print()\n",
    "print(to_markdown(\n",
    "    ['int16','int32','float32'],\n",
    "    ['mean','std','min','0.01%','99.99%','max']))\n",
    "print(to_markdown(\n",
    "    ['float64'],\n",
    "    ['mean','std','min','0.01%','99.99%','max'],\n",
    "    floatfmt='.1f'\n",
    ").split('\\n',2)[2])\n",
    "\n",
    "\n",
    "## Convert datafiles stats to markdown\n",
    "filesizes = !! du -h raw.csv data.parquet downsample.parquet\n",
    "filesizes = [n.split('\\t') for n in filesizes]\n",
    "files = pd.DataFrame(index=[\n",
    "    'Raw data','Cleaned data','(nonanomalous)','5% Downsample'])\n",
    "files['filename'] = [\n",
    "    filesizes[0][1],filesizes[1][1],'',filesizes[2][1]]\n",
    "files['filesize'] = [\n",
    "    filesizes[0][0],filesizes[1][0],'',filesizes[2][0]]\n",
    "files['number of rows'] = [\n",
    "    len_raw,len_data,len_nonanomalous,len_downsample]\n",
    "print()\n",
    "print(files.to_markdown())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
